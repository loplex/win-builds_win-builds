<h2>Build system hall of shame</h2>

<p>Building software, even more so packages, and even more for a system which is
little-used, like Windows, can be a painful experience. I don't mind mistakes
or limitations, especially when it comes to windows; well, more work for me but
that wouldn't be unexpected. However, I do mind when the mistakes are really
stupid.</p>

<h5>A small disclaimer</h5>
<p>I love the fact that all the software I've had to package is portable and
ported; I'm very grateful for that. Elements in this list must not be
considered as separate elements but as a whole, each of them contributing to
making the whole process of building packages frustrating and
sanity-harming.</p>

<p>If it were for one package, it wouldn't be a problem; if it were for two, if
it were for three, it wouldn't be an issue either; but when you have to deal
with dozens, things are different.</p>

<h5>Beers</h5>
<p>I'll happily pay a couple of (good) beers per bug fixed. Might not seem much
but I don't have unlimited funding and many of these bugs are very simple to
fix.</p>

<h3>zlib</h3>
  <h5>Makefiles</h5>
    <p>The "build-system" is a bunch of Makefiles. Some people say that having a
    number of triplet-specific makefiles is simpler than autotools. Maybe. But
    definitely not if you're going to end up with close to 30 makefiles.</p>

    <p>Cross-compilation support in autotools is also a great feature.</p>

    <p>Autotools also that advantage of usually not requiring additional work
    when a new architecture appears since everything is factored out. In
    particular, you don't have to worry because you'll have to work on a
    Makefile which starts with:
    <pre>
      # Makefile for zlib, derived from Makefile.dj2.
      # Modified for mingw32 by C. Spieler, 6/16/98.
      # Updated for zlib 1.2.x by Christian Spieler and Cosmin Truta, Mar-2003.
      # Last updated: 1-Aug-2003.
    </pre></p>

    <p>Alright. Vincent had done some work on that and I only had to change a
    couple of things to fit my needs.</p>

  <h5>Assembly</h5>
    <p>Zlib can have ASM code instead of C code for some functions for x86_32
    and x86_64. By default, it isn't enabled. One might wonder why and how
    faster it would be. I think noone knows. There is a file named
    "README.686". It reads:
    <pre>
      The speedup that this patch provides varies, depending on whether the
      compiler used to build the original version of zlib falls afoul of the
      PPro's speed traps. My own tests show a speedup of around 10-20% at
      the default compression level, and 20-30% using -9, against a version
      compiled using gcc 2.7.2.3. Your mileage may vary.
      [...]
      April, 1998
    </pre></p>
    
    <p>Below in the file, Brian Raiter who wrote this code gives an update: for
    a Pentium 4 and an Athlon64, the code is supposedly 8% faster than code
    generated by GCC 4.1, from April 2007. Besides the lack of hard data and
    precise numbrs, that was 5 years ago and GCC has evolved a lot since
    then.</p>

    <p>So, the question: how do I know whether I should enable ASM or not? Of
    course, I could benchmark myself but actually, the code doesn't even look
    maintained. I believe it should just be removed; it's not taken care of
    anyway.</p>

<h3>fontconfig</h3>
  <p>When cross-compiling, fontconfig needs that you configure it with a
  --with-arch setting because it can't determine it by itself.</p>

  <p>Well, that's a bit embarassing. Cross-compiling means setting
  --host=i686-w64-mingw32 or --host=x86_64-w64-mingw32 for instance: it looks
  like the architecture is written in full. Or maybe an architecture is not
  i686/x86_64 but I don't know since the switch wasn't documented properly. I
  believe this value is used because fontconfig has a binary cache which format
  is architecture-dependant but that's a speculation from a quick reading of
  the code.</p>

  <p>Anyway, the following will give the arch as I'm setting it:
  <pre>
    arch="$(echo i686-w64-mingw32 | cut -f1 -d-)"
  </pre>
  I think that little shell script would work fine a configure script...</p>

  <p>PS: I wonder if building for a given host won't automatically define CPP
  data too.</p>

<h3>libpng</h3>
  <p>Libpng, oh, libpng. A few days ago, I mentionned packaging libng on IRC,
  someone thought an update had been released and said the h√¶morrhoids had
  started.</p>

  <h5>Version numbers</h5>
    <p>Start by reading <a
      href="http://www.akkadia.org/drepper/dsohowto.pdf">How to Write Shared
      Libraries</a> by Ulrich Drepper.</p>

    <p>I've been told the design of that autotools-based build system was
    awful.  I don't know for sure since I haven't looked at it myself and to be
    honest, I'd be fine with it but such crap is just too bad (also, your
    indenting sucks):
    <pre>
      # do evil things to libpng to cause libpng@PNGLIB_MAJOR@@PNGLIB_MINOR@ to be used
      install-exec-hook:
        cd $(DESTDIR)$(bindir); rm -f libpng-config
        cd $(DESTDIR)$(bindir); $(LN_S) $(PNGLIB_BASENAME)-config libpng-config
        @set -x;\
        cd $(DESTDIR)$(libdir);\
        for ext in a la so so.@PNGLIB_MAJOR@@PNGLIB_MINOR@.@PNGLIB_RELEASE@ sl dylib dll.a; do\
          rm -f libpng.$$ext;\
          if test -f $(PNGLIB_BASENAME).$$ext; then\
            $(LN_S) $(PNGLIB_BASENAME).$$ext libpng.$$ext;\
          fi;\
        done
    </pre>

    It's great to have .dll and .dll.a files removed. Really great. All that
    because instead of incrementing the major version number, you're
    incrementing the minor one, *everywhere*. If you break the API, increase
    the major version number.

  <h5>libpng-config</h5>
    Just don't provide these kind of crap. No excuse now. And don't talk about
    backward compatibility since you're already doing awful things with version
    numbers. Use pkg-config.

<h3>lua</h3>
  <p>Dear lua devs, you've failed hard here. And you're doing worse and
  worse.</p>

  <h5>Build system? Which build system?</h5>
    <p>Ok, there's actually a build system.</p>

    <p>Not very useful nor usable however.</p>

    <p>Not very straightforward either actually.</p>

  <h5>Let's remove files from the source archive! Why? Because!</h5>
    <p>The 5.1.x releases of lua had several files which are now gone in the
    5.2.x releases. These files were uterly useless and I really support this
    move.  Space is expensive and small text files, especially when compressed,
    are really something which we cannot afford with the current economic
    crisis.</p>

    <p>That's why I've been happy to see files such as lua.pc, COPYRIGHT,
    README, HISTORY, and INSTALL disappear.</p>

    <p>Piss-poor changelogs, non-standard build procedures with catches
    everywhere, no info, thanks lua devs.</p>

  <h5>Hard-coded paths, no installation procedure; must be a guess game.</h5>
    <p>That's probably an all-time favorite: hard-coded paths to /usr/local.<p>

    <p>Is there a better way to show you haven't understood a thing about
    packaing, distributions and the use of "local"? Well, yes: don't tell about
    theses paths.</p>

    <p>So, you have to change paths in src/luaconf.h and in lua.pc. Well, not
    in lua.pc since it's not shipped anymore. That's what you call bug
    solving!</p>

  <h5>Better: hard-coded file extensions.</h5>
    <p>Hard-coding paths was a bit too common for lua developers I guess and
    they had to do something special. Or maybe they thought "a.out" was a good
    default name for executables on windows. Sed to the rescue:
    <pre>
      sed -i '/#define OUTPUT[ ]\+PROGNAME "\.out"/ s/\.out/.exe/' src/luac.c
    </pre>
    </p>

<h3>curl, c-ares</h3>
  <h5>Personal test, wrong algorithm, no cleverness.</h5>
    <p>It seems that curl and c-ares need to find the exact prototype of the
    recvfrom() function and have a corresponding test in configure.</p>

    <p>You'll start noticing something wrong when configure stays on the same
    test for several minutes, eats your CPU and the output in config.log seems
    to show it is looping forever trying to compile the same C code and
    failing.</p>

    <p>And then you grep for "recvfrom" and find the following code in
    acinclude.m4:
      <pre>
        if test "$curl_cv_recvfrom" = "yes"; then
          AC_CACHE_CHECK([types of args and return type for recvfrom],
            [curl_cv_func_recvfrom_args], [
            curl_cv_func_recvfrom_args="unknown"
            for recvfrom_retv in 'int' 'ssize_t'; do
              for recvfrom_arg1 in 'int' 'ssize_t' 'SOCKET'; do
                for recvfrom_arg2 in 'char *' 'void *'; do
                  for recvfrom_arg3 in 'size_t' 'int' 'socklen_t' 'unsigned int'; do
                    for recvfrom_arg4 in 'int' 'unsigned int'; do
                      for recvfrom_arg5 in 'struct sockaddr *' 'void *' 'const struct sockaddr *'; do
                        for recvfrom_arg6 in 'socklen_t *' 'int *' 'unsigned int *' 'size_t *' 'void *'; do
                          if test "$curl_cv_func_recvfrom_args" = "unknown"; then
                            AC_COMPILE_IFELSE([
                              AC_LANG_PROGRAM([[
        [...]
      </pre>
    </p>

    <p>As a programmer, you should have acquired a gut feeling when writing
    nested loops. Starting at 2 loops. At 3, you should really feel bad. And if
    you ever reach 4, it should make you ill. Now, 7 nested loops...</p>

    <p>So, let's do some maths: 2 possible return values, 3 possible first
    argument, then 2, then 4, 2, 3, 5. That makes 2*3*2*4*2*3*5 = 1440 possible
    combinations. Considering a test will take at least 100ms, you're good for
    up to at least 2 minutes and 20 seconds.</p>

    <p>Are there really 1440 possible prototypes which are all
    equaly-likely?</p>

    <p>There are two obvious improvements possible. The first, and possibly
    simplest, is to do some early tests for the most common systems. From very
    rough measurements, on my
    not-terribly-fast-but-still-fast-enough-that-I-build-absolutely-everything-on-it-laptop,
    it takes me 2 minutes to pass the test for linux64, which is arguably the
    most common case, and 4 minutes for i686-w64-mingw32 which is a very common
    one too.</p>

    <p>The second solution is probably the best approach (I haven't tried
    writing the code myself): test parameters one after the other instead of
    all at once. It's actually pretty simple: try all the possibilities for the
    return value, once you found it, try the first argument, then the second
    one, and so on. That would reduce the number of tests from 1440 to
    3+2+4+2+3+5 = 17.</p>

<h3>gtk+2</h3>
  <p>I had good hopes with gtk+2 which I expected to be well-tested.</p>

  <h5>Build system for 2.24 which doesn't even work on linux.</h5>
    <p>It turns out it seems the build system doesn't work as-is even on linux.
    On slackware, the build script runs libtoolize and autoreconf.</p>

  <h5>Undefined references</h5>
    <p>Not much to say: nothing special but something which could never have
    worked so no excuse: the 2.24 release just hasn't been tested.
    <pre>
      sed -i -e 's/GTK_PACKAGES="atk cairo gdk-pixbuf-2.0 gio-2.0/\0 gmodule-2.0/' configure.in
    </pre>
    </p>

    <p>Well, slackware has been carrying a patch to fix building and installing
    the tutorial too so I guess some things are never tested anyway.</p>

  <h5>Requiring GTK+ to be installed on the build machine, and failing at
    it.</h5>
    <p>So, you start by configuring gtk+2, it works fine. You build, it builds almost completely and then fails:
    <pre>
      no --force --ignore-theme-index [...]
      /bin/sh: no: command not found
    </pre></p>

    <p>Well, there's a "false" command, but no "no" command. Let's see the
    corresponding code in Makefile.am:
    <pre>
      $(gtk_update_icon_cache_program) --force --ignore-theme-index
    </pre></p>

    <p>Alright. There's probably something in the configure file, and since
    you've read it, you remember seeing something:
    <pre>
      checking for gtk-update-icon-cache... no
    </pre></p>

    <p>Enough said I think: no checking.</p>

<h3>sqlite3</h3>
  <p>When I started packaging sqlite3, I expected it not to work. I was
  expecting a makefile for each different architecture. It turned out it had an
  autotools-based system, and a few makefiles for some architectures.</p>

  But hopefully, it has also provided quite a lot of entertainment.


